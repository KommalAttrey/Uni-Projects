{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUCKfC_-Li2O",
        "outputId": "71212315-49f2-4f47-f059-cd5783225b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "The provided code reads XML content from a file and prints the first 100 lines of the XML content. The **read_xml_from_file** function is defined to read XML content from a file.\n",
        "It takes the file path as a parameter. It uses a **try-except** block to handle potential exceptions. Inside the try block, it opens the file in read mode using the with statement. It reads the XML content from the file using the **readlines()** method, which returns a list of lines. Finally, it returns the XML content as a list of lines. If a FileNotFoundError occurs, it prints \"File not found.\" If any other exception occurs, it prints \"An error occurred:\" along with the exception details.\n",
        "The **file_path** variable is assigned the path to the .txt file containing the XML content. The read_xml_from_file function is called with the file_path as an argument, and the returned XML content is stored in the **xml_lines** variable. If xml_lines is not None (i.e., if the file was successfully read), it prints the first 100 lines of the XML content. It uses list slicing **(xml_lines[:100])** to get the first 100 lines. The **join()** method is used to concatenate the lines into a single string for printing. Finally, the code joins all the XML lines into a single string using join() and stores it in the xml_data variable."
      ],
      "metadata": {
        "id": "oZZVhdqhT9PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_xml_from_file(file_path):\n",
        "    try:\n",
        "        # Open the file in read mode\n",
        "        with open(file_path, 'r') as file:\n",
        "            # Read the XML content from the file\n",
        "            xml_content = file.readlines()\n",
        "\n",
        "            # Return the XML content as a list of lines\n",
        "            return xml_content\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found.\")\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "\n",
        "# Provide the path to your .txt file containing XML content\n",
        "file_path = '/content/drive/Shareddrives/FIT5196_S1_2024/A1/Students data/Task 1/Group065.txt'\n",
        "\n",
        "# Read XML content from the file\n",
        "xml_lines = read_xml_from_file(file_path)\n",
        "\n",
        "# If xml_lines is not None, print the first 100 lines\n",
        "if xml_lines:\n",
        "    print(\"First 100 lines of XML content:\")\n",
        "    print(''.join(xml_lines[:100]))\n",
        "\n",
        "\n",
        "    # Join the XML lines into a single string\n",
        "    xml_data = ''.join(xml_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFk70VEpMUL4",
        "outputId": "790435d4-80ab-4404-c350-256f467330fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 100 lines of XML content:\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<!DOCTYPE trademark-assignments [<!-- DOCUMENT TYPE DEFINITION FOR TRADEMARK ASSIGNMENTS\n",
            "Reference this DTD as PUBLIC \"-//USPTO//DTD TRADEMARK_ASSIGNMENTS V1.0 2013-09-05//EN\" \n",
            "\n",
            "Contact:\n",
            "U.S. Patent and Trademark Office\n",
            "Electronic Information Products Division\n",
            "P.O. Box 1450\n",
            "Alexandria, VA 22313\n",
            "ipd@uspto.gov\n",
            "\n",
            "***** START REVISION HISTORY *****\n",
            "12/01/2000 Added ACK_DATE (Date Acknowledged) to PARTY element.\n",
            "03/06/2002 Updated element names to conform to PTO Enterprise standard element names.\n",
            "05/14/2002 Updated property element to include Trademark Law Treaty values\n",
            "05/19/2003 Added LAST-UPDATE-DATE element to the group element <assignment>.\n",
            "08/28/2003 Updated property group element to add optional element International-Registration-Number.\n",
            "Updated property group elements serial-no, registration-no with optional parameter\n",
            "(These fields may not be available when an international registration number is present).\n",
            "10/10/2003 Removed space between registration-no element and the question mark attribute\n",
            "10/10/2003 Provided documentation statement for International Registration Number\n",
            "09/05/2013 Added new elements for composed of data that contains an XML structure for sub-entities.\n",
            "***** END REVISION HISTORY ********\n",
            "<trademark-assignments>\n",
            "  <version>\n",
            "    <version-no>1.0</version-no>\n",
            "    <version-date>20130910</version-date>\n",
            "  </version>\n",
            "  <action-key-code>DA</action-key-code>\n",
            "  <transaction-date>20240202</transaction-date>\n",
            "  <assignment-information>  \n",
            "<assignment-entry>\n",
            "      <assignment>\n",
            "          <reel-no>6016</reel-no>\n",
            "          <frame-no>0060</frame-no>\n",
            "          <last-update-date>20170323</last-update-date>\n",
            "          <purge-indicator>N</purge-indicator>\n",
            "          <date-recorded>20170323</date-recorded>\n",
            "          <page-count>2</page-count>\n",
            "          <correspondent>\n",
            "              <person-or-organization-name>TELEFACTION A/S</person-or-organization-name>\n",
            "              <address-1>ALDERSROGADE 8, 2.</address-1>\n",
            "              <address-2>DK-2100 KØBENHAVN Ø</address-2>\n",
            "              <address-3>DENMARK</address-3>\n",
            "          </correspondent>\n",
            "          <conveyance-text>CHANGE OF ADDRESS</conveyance-text>\n",
            "      </assignment>\n",
            "      <assignors>\n",
            "          <assignor>\n",
            "              <person-or-organization-name>TELEFACTION A/S</person-or-organization-name>\n",
            "              <execution-date>20170104</execution-date>\n",
            "              <legal-entity-text>UNKNOWN</legal-entity-text>\n",
            "              <nationality>NOT PROVIDED</nationality>\n",
            "          </assignor>\n",
            "      </assignors>\n",
            "      <assignees>\n",
            "          <assignee>\n",
            "              <person-or-organization-name>TELEFACTION A/S</person-or-organization-name>\n",
            "              <address-1>ALDERSROGADE 8, 2.</address-1>\n",
            "              <city>DK-2100 KØBENHAVN Ø</city>\n",
            "              <country-name>DENMARK</country-name>\n",
            "              <legal-entity-text>UNKNOWN</legal-entity-text>\n",
            "              <nationality>NOT PROVIDED</nationality>\n",
            "          </assignee>\n",
            "      </assignees>\n",
            "      <properties>\n",
            "          <property>\n",
            "              <serial-no>79053956</serial-no>\n",
            "              <registration-no>3651300</registration-no>\n",
            "              <intl-reg-no>0929398</intl-reg-no>\n",
            "          </property>\n",
            "      </properties>\n",
            "     </assignment-entry>\n",
            "<assignment-entry>\n",
            "      <assignment>\n",
            "          <reel-no>4806</reel-no>\n",
            "          <frame-no>0981</frame-no>\n",
            "          <last-update-date>20120625</last-update-date>\n",
            "          <purge-indicator>N</purge-indicator>\n",
            "          <date-recorded>20120622</date-recorded>\n",
            "          <page-count>2</page-count>\n",
            "          <correspondent>\n",
            "              <person-or-organization-name>MICHAEL ELBEIN - HOVEY WILLIAMS LLP</person-or-organization-name>\n",
            "              <address-1>10801 MASTIN BLVD., SUITE 1000</address-1>\n",
            "              <address-2>OVERLAND PARK, KS 66210</address-2>\n",
            "          </correspondent>\n",
            "          <conveyance-text>NUNC PRO TUNC ASSIGNMENT EFFECTIVE 08/19/2005</conveyance-text>\n",
            "      </assignment>\n",
            "      <assignors>\n",
            "          <assignor>\n",
            "              <person-or-organization-name>STONEY POINT PRODUCTS, INC.</person-or-organization-name>\n",
            "              <execution-date>20120621</execution-date>\n",
            "              <legal-entity-text>CORPORATION</legal-entity-text>\n",
            "              <nationality>MINNESOTA</nationality>\n",
            "          </assignor>\n",
            "      </assignors>\n",
            "      <assignees>\n",
            "          <assignee>\n",
            "              <person-or-organization-name>BUSHNELL INC.</person-or-organization-name>\n",
            "              <address-1>9200 CODY</address-1>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "The **get_country** function is designed to extract the country information from the assignor or assignee data in the XML. It takes the **party_data (which represents the XML data for an assignor or assignee) as input** and returns the corresponding country based on the available information.\n",
        "\n",
        "It searches for the country name using the regular expression. If a country name is found, it checks if it matches any of the predefined variations for the United States, United Kingdom, or Canada. If a match is found, it returns the corresponding country code **(\"USA\", \"UK\", or \"CANADA\")**. If the country name doesn't match any of these variations, it returns the country name as is.\n",
        "\n",
        "If no country name is found, it searches **first for state and then nationality** information using the regular expression. If a state/nationality is found, it checks if it matches any of the predefined US states, UK countries, or Canadian provinces/territories given in a list. If a match is found, it returns the corresponding country code (\"USA\", \"UK\", or \"CANADA\").\n",
        "\n",
        "If no country, state, or nationality information is found, it returns **\"NA\"** to indicate that the country information is not available."
      ],
      "metadata": {
        "id": "BM2ZAOWEvyqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# Function to extract the country information from an assignor or assignee\n",
        "def get_country(party_data):\n",
        "    \"\"\"\n",
        "    This function takes the assignor or assignee data as input and extracts the country information.\n",
        "    It searches for the country name, state, and nationality in the data and returns the corresponding country.\n",
        "    If no country information is found, it returns \"NA\".\n",
        "    \"\"\"\n",
        "    # Search for the country name in the assignor or assignee data\n",
        "    country_name_match = re.search(r'<country-name>(.*?)</country-name>', party_data)\n",
        "    if country_name_match:\n",
        "        country_name = country_name_match.group(1)\n",
        "        # Check if the country name matches United States or its variations\n",
        "        if re.search(r'united states|usa|u\\.s\\.a\\.|u\\.s\\.|UNITED STATES|USA|U\\.S\\.A\\.|U\\.S\\.', country_name):\n",
        "            return \"USA\"\n",
        "        # Check if the country name matches United Kingdom or its variations\n",
        "        elif re.search(r'united kingdom|uk|u\\.k\\.|UNITED KINGDOM|UK|U\\.K\\.', country_name):\n",
        "            return \"UK\"\n",
        "        # Check if the country name matches Canada or its variations\n",
        "        elif re.search(r'canada|CANADA', country_name):\n",
        "            return \"CANADA\"\n",
        "        else:\n",
        "            return country_name\n",
        "    # Search for the state in the assignor data\n",
        "    state_match = re.search(r'<state>(.*?)</state>', party_data)\n",
        "    if state_match:\n",
        "        state = state_match.group(1)\n",
        "\n",
        "         # Check if the state matches any US state or district\n",
        "        usa_states = [\n",
        "            'ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT', 'DELAWARE', 'FLORIDA',\n",
        "            'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE',\n",
        "            'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA',\n",
        "            'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO',\n",
        "            'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS',\n",
        "            'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING', 'DISTRICT OF COLUMBIA'\n",
        "        ]\n",
        "        if state.upper() in usa_states:\n",
        "\n",
        "            return \"USA\"\n",
        "        # Check if the state matches any constituent country of the UK\n",
        "        uk_countries = ['ENGLAND', 'SCOTLAND', 'WALES', 'NORTHERN IRELAND']\n",
        "        if state.upper() in uk_countries:\n",
        "\n",
        "            return \"UK\"\n",
        "\n",
        "        # Check if the state matches any province or territory of Canada\n",
        "        canada_provinces_territories = [\n",
        "            'ALBERTA', 'BRITISH COLUMBIA', 'MANITOBA', 'NEW BRUNSWICK', 'NEWFOUNDLAND AND LABRADOR',\n",
        "            'NOVA SCOTIA', 'ONTARIO', 'PRINCE EDWARD ISLAND', 'QUEBEC', 'SASKATCHEWAN',\n",
        "            'NORTHWEST TERRITORIES', 'NUNAVUT', 'YUKON'\n",
        "        ]\n",
        "        if state.upper() in canada_provinces_territories:\n",
        "\n",
        "            return \"CANADA\"\n",
        "    # Search for the nationality in the assignor data\n",
        "    nationality_match = re.search(r'<nationality>(.*?)</nationality>', party_data)\n",
        "    if nationality_match:\n",
        "        nationality = nationality_match.group(1)\n",
        "\n",
        "         # Check if the nationality matches any US state or district\n",
        "        usa_states = [\n",
        "            'ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT', 'DELAWARE', 'FLORIDA',\n",
        "            'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE',\n",
        "            'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA',\n",
        "            'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO',\n",
        "            'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS',\n",
        "            'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING', 'DISTRICT OF COLUMBIA'\n",
        "        ]\n",
        "\n",
        "        if nationality.upper() in usa_states:\n",
        "\n",
        "            return \"USA\"\n",
        "\n",
        "        # Check if the nationality matches any constituent country of the UK\n",
        "        uk_countries = ['ENGLAND', 'SCOTLAND', 'WALES', 'NORTHERN IRELAND']\n",
        "        if nationality.upper() in uk_countries:\n",
        "\n",
        "            return \"UK\"\n",
        "\n",
        "        # Check if the nationality matches any province or territory of Canada\n",
        "        canada_provinces_territories = [\n",
        "            'ALBERTA', 'BRITISH COLUMBIA', 'MANITOBA', 'NEW BRUNSWICK', 'NEWFOUNDLAND AND LABRADOR',\n",
        "            'NOVA SCOTIA', 'ONTARIO', 'PRINCE EDWARD ISLAND', 'QUEBEC', 'SASKATCHEWAN',\n",
        "            'NORTHWEST TERRITORIES', 'NUNAVUT', 'YUKON'\n",
        "        ]\n",
        "        if nationality.upper() in canada_provinces_territories:\n",
        "\n",
        "            return \"CANADA\"\n",
        "\n",
        "        if nationality.upper() != \"NOT PROVIDED\":\n",
        "            return nationality\n",
        "    # Return \"NA\" if no country information is found\n",
        "\n",
        "    return \"NA\"\n"
      ],
      "metadata": {
        "id": "ICPv07gIZ80O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "**re.search()** function is used to find the first occurrence of each pattern within the assignment_data string. re.search is used to find reel number, frame number, last update date, conveyance text and correspondant party within xml data.\n",
        "\n",
        "r before the string indicates a raw string literal, which treats backslashes as literal characters. **(\\d+)** is a capturing group that matches one or more digits (\\d+). A capturing group **(\\d{8})** is used to extract the 8-digit date value. (.*?) **bold text** is used to extract the text between the tags.\n",
        "\n",
        "**reel_no.group(1) if reel_no else '':** This is a conditional expression that checks if reel_no exists (i.e., not None). If it exists, it extracts the captured group at index 1 using reel_no.group(1). If reel_no is None, it returns an empty string ''. frame_no.group(1) if frame_no else '': Similarly, this conditional expression checks if frame_no exists. The two expressions are concatenated within the f-string to form the rf_id.\n",
        "\n",
        "**last_update_date_value[:4]** extracts the first 4 characters (year) from last_update_date_value.\n",
        "**last_update_date_value[4:6]** extracts characters at index 4 and 5 (month) from last_update_date_value.\n",
        "**last_update_date_value[6:]** extracts characters from index 6 onwards (day) from last_update_date_value.\n",
        "\n",
        "**re.findall()** function to extract assignor information from a string called assignment_data. **re.DOTALL** flag is used as the third argument to re.findall(). It allows the dot (.) metacharacter to match newline characters as well. Without this flag, the dot would match any character except newline.\n",
        "\n",
        "**company_indicators** is a list of strings that are commonly found in company or organization names. The expression **indicator in party_name.lower() for indicator in company_indicators** is a generator expression that checks if any indicator from company_indicators is present in the lowercase version of party_name. **re.sub()** is a function from the re module that replaces occurrences of a pattern with a replacement string.\n",
        "The first argument is the regex pattern: r'(?i)(Mr|Mrs|Miss|Ms|Mx|Sir|Dame|Dr|Cllr|Lady|Lord)\\. **(?i)** is a flag that makes the pattern case-insensitive. The pattern matches any of the specified titles followed by a dot and a space."
      ],
      "metadata": {
        "id": "b5TL_smp6kkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process an assignment and extract relevant information\n",
        "def process_assignment(assignment_data):\n",
        "    \"\"\"\n",
        "    This function takes an assignment entry as input and extracts relevant information from it.\n",
        "    It extracts the reel number, frame number, last update date, conveyance text, correspondent party,\n",
        "    assignor information, assignee information, and property count.\n",
        "    It returns a JSON object containing the extracted information.\n",
        "    \"\"\"\n",
        "    # Extract reel number, frame number, last update date, conveyance text, and correspondent party\n",
        "    reel_no = re.search(r'<reel-no>(\\d+)</reel-no>', assignment_data)\n",
        "    frame_no = re.search(r'<frame-no>(\\d+)</frame-no>', assignment_data)\n",
        "    last_update_date = re.search(r'<last-update-date>(\\d{8})</last-update-date>', assignment_data)\n",
        "    conveyance_text = re.search(r'<conveyance-text>(.*?)</conveyance-text>', assignment_data)\n",
        "    correspondent_party = re.search(r'<person-or-organization-name>(.*?)</person-or-organization-name>', assignment_data)\n",
        "\n",
        "    # Create the rf_id by combining reel number and frame number\n",
        "    rf_id = f\"{reel_no.group(1) if reel_no else ''}{frame_no.group(1) if frame_no else ''}\"\n",
        "\n",
        "    # Format the last update date\n",
        "    last_update_date_formatted = \"\"\n",
        "    if last_update_date:\n",
        "        last_update_date_value = last_update_date.group(1)\n",
        "        last_update_date_formatted = f\"{last_update_date_value[:4]}-{last_update_date_value[4:6]}-{last_update_date_value[6:]}\"\n",
        "\n",
        "    # Extract conveyance text and correspondent party values\n",
        "    conveyance_text_value = conveyance_text.group(1) if conveyance_text else \"\"\n",
        "    correspondent_party_value = correspondent_party.group(1) if correspondent_party else \"\"\n",
        "\n",
        "    # Extract assignor information\n",
        "    assignors_info = re.findall(r'<assignor>(.*?)</assignor>', assignment_data, re.DOTALL)\n",
        "    assignors = []\n",
        "\n",
        "    for assignor in assignors_info:\n",
        "        # Extract party name and remove titles\n",
        "        party_name = re.search(r'<person-or-organization-name>(.*?)</person-or-organization-name>', assignor).group(1)\n",
        "        # Check if the party name contains any company or organization indicators\n",
        "        company_indicators = ['company', 'corporation', 'incorporated', 'limited', 'ltd', 'llc', 'Inc', 'co', 'corp', 'inc']\n",
        "        is_company = any(indicator in party_name.lower() for indicator in company_indicators)\n",
        "\n",
        "        if not is_company:\n",
        "            party_name = re.sub(r'(?i)(Mr|Mrs|Miss|Ms|Mx|Sir|Dame|Dr|Cllr|Lady|Lord)\\. ', '', party_name)\n",
        "\n",
        "        # Extract date acknowledged and format it\n",
        "        date_acknowledged_match = re.search(r'<ack-date>(\\d{8})</ack-date>', assignor)\n",
        "        date_acknowledged = date_acknowledged_match.group(1) if date_acknowledged_match else \"NA\"\n",
        "\n",
        "        if date_acknowledged != \"NA\":\n",
        "            date_acknowledged = f\"{date_acknowledged[:4]}-{date_acknowledged[4:6]}-{date_acknowledged[6:]}\"\n",
        "\n",
        "        # Extract execution date and format it\n",
        "        execution_date_match = re.search(r'<execution-date>(\\d{8})</execution-date>', assignor)\n",
        "        execution_date = execution_date_match.group(1) if execution_date_match else \"NA\"\n",
        "\n",
        "        if execution_date != \"NA\":\n",
        "            execution_date = f\"{execution_date[:4]}-{execution_date[4:6]}-{execution_date[6:]}\"\n",
        "\n",
        "        # Get the country information for the assignor\n",
        "        country = get_country(assignor)\n",
        "\n",
        "        # Extract legal entity text\n",
        "        legal_entity_text_match = re.search(r'<legal-entity-text>(.*?)</legal-entity-text>', assignor)\n",
        "        legal_entity_text = legal_entity_text_match.group(1) if legal_entity_text_match else \"NA\"\n",
        "\n",
        "        # Append the assignor information to the assignors list\n",
        "        assignors.append({\n",
        "            \"party-name\": party_name,\n",
        "            \"date-acknowledged\": date_acknowledged,\n",
        "            \"execution-date\": execution_date,\n",
        "            \"country\": country,\n",
        "            \"legal-entity-text\": legal_entity_text\n",
        "        })\n",
        "\n",
        "    # Extract assignee information\n",
        "    assignees_info = re.findall(r'<assignee>(.*?)</assignee>', assignment_data, re.DOTALL)\n",
        "    assignees = []\n",
        "\n",
        "    for assignee in assignees_info:\n",
        "        # Extract party name and remove titles\n",
        "        party_name = re.search(r'<person-or-organization-name>(.*?)</person-or-organization-name>', assignee).group(1)\n",
        "        # Check if the party name contains any company or organization indicators\n",
        "        company_indicators = ['company', 'corporation', 'incorporated', 'limited', 'ltd', 'llc', 'Inc', 'co', 'corp', 'inc']\n",
        "        is_company = any(indicator in party_name.lower() for indicator in company_indicators)\n",
        "\n",
        "        if not is_company:\n",
        "            party_name = re.sub(r'(?i)(Mr|Mrs|Miss|Ms|Mx|Sir|Dame|Dr|Cllr|Lady|Lord)\\. ', '', party_name)\n",
        "        # Get the country information for the assignee\n",
        "        country = get_country(assignee)\n",
        "\n",
        "        # Extract legal entity text\n",
        "        legal_entity_text_match = re.search(r'<legal-entity-text>(.*?)</legal-entity-text>', assignee)\n",
        "        legal_entity_text = legal_entity_text_match.group(1) if legal_entity_text_match else \"NA\"\n",
        "\n",
        "        # Append the assignee information to the assignees list\n",
        "        assignees.append({\n",
        "            \"party-name\": party_name,\n",
        "            \"country\": country,\n",
        "            \"legal-entity-text\": legal_entity_text\n",
        "        })\n",
        "\n",
        "    # Count the number of properties in the assignment\n",
        "    properties = re.findall(r'<property>(.*?)</property>', assignment_data, re.DOTALL)\n",
        "    property_count = len(properties)\n",
        "\n",
        "    # Create the JSON output for the assignment\n",
        "    json_output = {\n",
        "        rf_id: {\n",
        "            \"last-update-date\": last_update_date_formatted,\n",
        "            \"conveyance-text\": conveyance_text_value,\n",
        "            \"correspondent_party\": correspondent_party_value,\n",
        "            \"assignors_info\": assignors,\n",
        "            \"assignees_info\": assignees,\n",
        "            \"property-count\": str(property_count)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return json_output"
      ],
      "metadata": {
        "id": "oMnAuI2lOLP7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "It combines the individual JSON outputs into a single dictionary called **final_json_output**. The **update()** method is used to merge the key-value pairs from each JSON output into the final_json_output dictionary. It writes the final_json_output dictionary to a JSON file specified by output_file using the **json.dump()** function. The **indent=4** parameter ensures that the JSON output is formatted with proper indentation for readability."
      ],
      "metadata": {
        "id": "-wOROV8VZXhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read XML content from the file\n",
        "xml_data = ''.join(xml_lines)\n",
        "\n",
        "# Extract individual assignments using regular expressions\n",
        "assignments = re.findall(r'<assignment-entry>(.*?)</assignment-entry>', xml_data, re.DOTALL)\n",
        "\n",
        "# Process each assignment and generate JSON output\n",
        "json_outputs = []\n",
        "for assignment in assignments:\n",
        "    json_output = process_assignment(assignment)\n",
        "    json_outputs.append(json_output)\n",
        "\n",
        "# Combine the JSON outputs into a single dictionary\n",
        "final_json_output = {}\n",
        "for json_output in json_outputs:\n",
        "    final_json_output.update(json_output)\n",
        "\n",
        "# Write the final JSON output to a file\n",
        "output_file = \"task1_65.json\"\n",
        "with open(output_file, \"w\") as file:\n",
        "    json.dump(final_json_output, file, indent=4)\n",
        "\n",
        "print(f\"JSON output written to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNbBJijz3T6A",
        "outputId": "c7337a33-cea1-4d5c-ea13-fc993b1f2395"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON output written to task1_65.json\n"
          ]
        }
      ]
    }
  ]
}